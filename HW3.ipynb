{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W5AsCKO5Nqsh",
    "outputId": "7358d0fd-8120-49c4-b7ad-9724691bdf99",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /usr/local/spark-3.1.2-bin-hadoop3.2/python (3.1.2)\r\n",
      "Requirement already satisfied: py4j==0.10.9 in /opt/conda/lib/python3.9/site-packages (from pyspark) (0.10.9)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "E3Q9g_UyNxS6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/08/30 18:49:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder\\\n",
    "    .master(\"local[2]\")\\\n",
    "    .appName(\"Lesson_2\")\\\n",
    "    .config(\"spark.executor.instances\",2)\\\n",
    "    .config(\"spark.executor.memory\",'2g')\\\n",
    "    .config(\"spark.executor.cores\",1)\\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVGNGR7pN1KC"
   },
   "source": [
    "# Самостоятельная работа к уроку 3\n",
    "На уроке мы попробовали оконные и пользовательские функции. Теперь закрепим полученные знания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agigNChqOHnK"
   },
   "source": [
    "## Данные: [google drive: raw_sales.csv](https://drive.google.com/file/d/1G2N7Mnt4-Tqz4JdJxutGDMbJiOr32kZp/view?usp=sharing)\n",
    "\n",
    " Каждая строчка это продажа жилья, которая состоит из следующих полей (думаю описание не требуется):\n",
    "*   date of sale\n",
    "*   price\n",
    "*   property type\n",
    "*   number of bedrooms\n",
    "*   4digit postcode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xisyFowtQgx-"
   },
   "source": [
    "## Задание 1\n",
    "Добавьте к таблице следующие поля:\n",
    "*  Средняя стомость 10 проданных домов до текущего в том же районе (4digit postcode) (1 балл)\n",
    "*  Средняя стомость 10 проданных домов после текущего в том же районе (4digit postcode) (1 балл)\n",
    "*  Стоимость последнего проданного дома до текущего (1 балл)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NsUKEiRTUOtT"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "df = spark.read.csv('raw_sales.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+-------+------------+--------+\n",
      "|           datesold|postcode|  price|propertyType|bedrooms|\n",
      "+-------------------+--------+-------+------------+--------+\n",
      "|2007-07-08 00:00:00|    2600| 327000|       house|       1|\n",
      "|2007-08-16 00:00:00|    2600| 790000|       house|       4|\n",
      "|2007-12-05 00:00:00|    2600| 825000|       house|       3|\n",
      "|2009-03-28 00:00:00|    2600| 722000|       house|       4|\n",
      "|2008-04-24 00:00:00|    2600| 292500|       house|       1|\n",
      "|2008-06-19 00:00:00|    2600| 765000|       house|       5|\n",
      "|2008-07-29 00:00:00|    2600| 927000|       house|       4|\n",
      "|2008-09-02 00:00:00|    2600|1380000|       house|       5|\n",
      "|2008-09-08 00:00:00|    2600| 740000|       house|       3|\n",
      "|2008-09-17 00:00:00|    2600| 720000|       house|       3|\n",
      "|2008-09-22 00:00:00|    2600| 690000|       house|       4|\n",
      "|2008-11-18 00:00:00|    2600| 635000|       house|       3|\n",
      "|2008-11-18 00:00:00|    2600| 950000|       house|       3|\n",
      "|2008-11-21 00:00:00|    2600| 730000|       house|       3|\n",
      "|2008-12-22 00:00:00|    2600| 855000|       house|       3|\n",
      "|2008-12-24 00:00:00|    2600|1057500|       house|       4|\n",
      "|2009-01-20 00:00:00|    2600|1150000|       house|       4|\n",
      "|2009-01-22 00:00:00|    2600| 575000|       house|       3|\n",
      "|2009-02-13 00:00:00|    2600| 880000|       house|       4|\n",
      "|2009-03-17 00:00:00|    2600|1015000|       house|       4|\n",
      "+-------------------+--------+-------+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.registerTempTable('df')\n",
    "spark.sql('select * from df order by postcode limit 20').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "windSpecBefore = Window\\\n",
    "    .partitionBy('postcode')\\\n",
    "    .orderBy('datesold')\\\n",
    "    .rowsBetween(Window.currentRow, 9)\n",
    "windSpecAfter = Window\\\n",
    "    .partitionBy('postcode')\\\n",
    "    .orderBy('datesold')\\\n",
    "    .rowsBetween(-9, Window.currentRow)\n",
    "windSpecPrev = Window\\\n",
    "    .partitionBy('postcode')\\\n",
    "    .orderBy('datesold')\\\n",
    "    .rowsBetween(-1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stat = df.withColumn('avg_before', F.avg('price').over(windSpecBefore))\\\n",
    "    .withColumn('avg_after', F.avg('price').over(windSpecAfter))\\\n",
    "    .withColumn('prev', F.avg('price').over(windSpecPrev))\\\n",
    "    .withColumn('avg_before', F.lag('avg_before', 10).over(Window.partitionBy('postcode').orderBy('datesold')))\\\n",
    "    .withColumn('avg_after', F.lead('avg_after', 10).over(Window.partitionBy('postcode').orderBy('datesold')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat.registerTempTable('stat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SoKJ_YOBUQGL"
   },
   "source": [
    "## Задание 2\n",
    "Найдите среднюю цену жилья для каждого года и приджойните эти данные к таблице из задания 1. (2 балла)\n",
    "\n",
    "\n",
    "*(left join on a.year(date of sale) = b.year, где a - таблица из первого задания, а b таблица после группировки)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "emn6tIDVQWi-",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:===============================================>       (171 + 3) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+-------+------------+--------+----------+---------+---------+--------------+\n",
      "|           datesold|postcode|  price|propertyType|bedrooms|avg_before|avg_after|     prev|year_avg_price|\n",
      "+-------------------+--------+-------+------------+--------+----------+---------+---------+--------------+\n",
      "|2018-07-24 00:00:00|    2600| 320000|        unit|       2| 1274000.0| 724450.0|1800000.0|      660701.0|\n",
      "|2018-06-15 00:00:00|    2600|1510000|       house|       4|  957000.0|1157900.0| 421000.0|      660701.0|\n",
      "|2018-07-09 00:00:00|    2600|1800000|       house|       3| 1171000.0| 682950.0|1320000.0|      660701.0|\n",
      "|2018-05-24 00:00:00|    2600|1265000|       house|       3| 1166500.0|1099700.0|1180000.0|      660701.0|\n",
      "|2018-06-14 00:00:00|    2600| 421000|        unit|       1| 1044900.0|1263900.0| 770000.0|      660701.0|\n",
      "|2018-06-22 00:00:00|    2600| 468000|        unit|       2| 1099700.0|1069000.0| 355000.0|      660701.0|\n",
      "|2018-07-07 00:00:00|    2600|1320000|        unit|       3| 1159000.0| 797950.0|1470000.0|      660701.0|\n",
      "|2018-05-11 00:00:00|    2600|1300000|       house|       4| 1262600.0| 957000.0|1610000.0|      660701.0|\n",
      "|2018-05-21 00:00:00|    2600|1180000|       house|       3| 1173500.0|1190700.0| 489000.0|      660701.0|\n",
      "|2018-05-26 00:00:00|    2600|1180000|       house|       4| 1097500.0|1081000.0| 970000.0|      660701.0|\n",
      "|2018-06-06 00:00:00|    2600| 770000|        unit|       2| 1128900.0|1274000.0|1200000.0|      660701.0|\n",
      "|2018-04-30 00:00:00|    2600|1305000|       house|       4| 1541600.0|1128900.0| 686000.0|      660701.0|\n",
      "|2018-06-18 00:00:00|    2600| 355000|        unit|       2| 1190700.0|1048300.0|2701000.0|      660701.0|\n",
      "|2018-06-27 00:00:00|    2600|1495000|        unit|       3| 1049500.0| 953450.0| 468000.0|      660701.0|\n",
      "|2018-06-30 00:00:00|    2600|1470000|       house|       4| 1081000.0| 850950.0|1495000.0|      660701.0|\n",
      "|2018-03-28 00:00:00|    2600|1550000|       house|       4| 1786600.0|1149600.0|2285000.0|      660701.0|\n",
      "|2018-05-01 00:00:00|    2600|1610000|       house|       4| 1297100.0|1044900.0|1305000.0|      660701.0|\n",
      "|2018-05-12 00:00:00|    2600|1405000|       house|       4| 1164100.0| 967500.0|1300000.0|      660701.0|\n",
      "|2018-05-15 00:00:00|    2600| 489000|        unit|       1| 1149600.0|1038600.0|1405000.0|      660701.0|\n",
      "|2018-03-01 00:00:00|    2600|2250000|       house|       5| 1179100.0|1481600.0|1700000.0|      660701.0|\n",
      "|2018-05-25 00:00:00|    2600| 970000|       house|       2| 1158000.0|1049500.0|1265000.0|      660701.0|\n",
      "|2018-06-02 00:00:00|    2600| 690000|        unit|       2| 1139000.0|1159000.0|1180000.0|      660701.0|\n",
      "|2018-06-05 00:00:00|    2600|1200000|       house|       4| 1139400.0|1171000.0| 690000.0|      660701.0|\n",
      "|2018-02-23 00:00:00|    2600|1630000|       house|       4| 1098100.0|1778600.0|1465000.0|      660701.0|\n",
      "|2018-04-13 00:00:00|    2600|1350000|       house|       4| 1571600.0|1158000.0|1250000.0|      660701.0|\n",
      "|2018-06-16 00:00:00|    2600|1200000|       house|       3|  967500.0|1139900.0|1510000.0|      660701.0|\n",
      "|2018-06-16 00:00:00|    2600|2701000|       house|       4| 1038600.0| 963800.0|1200000.0|      660701.0|\n",
      "|2018-04-06 00:00:00|    2600|1250000|       house|       3| 1616600.0|1166500.0| 250000.0|      660701.0|\n",
      "|2018-04-17 00:00:00|    2600| 686000|        unit|       2| 1534800.0|1139400.0| 765000.0|      660701.0|\n",
      "|2018-04-16 00:00:00|    2600| 765000|        unit|       2| 1506600.0|1139000.0|1575000.0|      660701.0|\n",
      "|2018-04-14 00:00:00|    2600|1575000|       house|       3| 1481600.0|1097500.0|1350000.0|      660701.0|\n",
      "|2007-08-16 00:00:00|    2600| 790000|       house|       4|      null| 698350.0| 327000.0|      522377.0|\n",
      "|2018-03-24 00:00:00|    2600|2285000|       house|       3| 1704600.0|1164100.0|1955000.0|      660701.0|\n",
      "|2018-03-10 00:00:00|    2600|1325000|       house|       4| 1365100.0|1506600.0|2250000.0|      660701.0|\n",
      "|2018-04-03 00:00:00|    2600| 250000|        unit|       1| 1778600.0|1173500.0|1550000.0|      660701.0|\n",
      "|2018-03-10 00:00:00|    2600| 483000|        unit|       1| 1377600.0|1534800.0|1325000.0|      660701.0|\n",
      "|2018-03-23 00:00:00|    2600|1955000|       house|       4| 1556200.0|1262600.0|3750000.0|      660701.0|\n",
      "|2018-03-17 00:00:00|    2600|3750000|       house|       5| 1346200.0|1297100.0| 618000.0|      660701.0|\n",
      "|2018-03-16 00:00:00|    2600| 618000|        unit|       2| 1392900.0|1541600.0| 483000.0|      660701.0|\n",
      "|2007-07-08 00:00:00|    2600| 327000|       house|       1|      null| 708350.0|     null|      522377.0|\n",
      "|2018-02-23 00:00:00|    2600|1870000|       house|       4| 1110100.0|1616600.0|1630000.0|      660701.0|\n",
      "|2018-02-08 00:00:00|    2600|1650000|       house|       4|  995050.0|1556200.0|1085000.0|      660701.0|\n",
      "|2018-01-24 00:00:00|    2600|1085000|       house|       3| 1024050.0|1346200.0| 330000.0|      660701.0|\n",
      "|2018-01-08 00:00:00|    2600| 330000|       house|       2| 1111050.0|1392900.0|1200000.0|      660701.0|\n",
      "|2018-02-24 00:00:00|    2600|1700000|       house|       4| 1154100.0|1571600.0|1870000.0|      660701.0|\n",
      "|2018-08-04 00:00:00|    2600| 675000|        unit|       2| 1048300.0| 693650.0|1200000.0|      660701.0|\n",
      "|2018-01-03 00:00:00|    2600|1200000|       house|       4| 1216050.0|1377600.0| 390000.0|      660701.0|\n",
      "|2007-12-05 00:00:00|    2600| 825000|       house|       3|      null| 679350.0| 790000.0|      522377.0|\n",
      "|2018-02-10 00:00:00|    2600|1465000|       house|       4| 1055350.0|1786600.0| 471000.0|      660701.0|\n",
      "|2018-02-08 00:00:00|    2600| 471000|        unit|       1| 1056250.0|1704600.0|1650000.0|      660701.0|\n",
      "+-------------------+--------+-------+------------+--------+----------+---------+---------+--------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql('select *, round(sum(price) over ( partition by year(datesold) )/(count(datesold) over(partition by year(datesold)))) as year_avg_price from stat order by postcode').show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark.sql('select distinct year(datesold) as YR, round(sum(price) over ( partition by year(datesold) )/(count(datesold) over(partition by year(datesold)))) as year_avg_price from stat order by YR').createOrReplaceTempView(\"avg_price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+------+------------+--------+----------+---------+--------+----+\n",
      "|           datesold|postcode| price|propertyType|bedrooms|avg_before|avg_after|    prev|year|\n",
      "+-------------------+--------+------+------------+--------+----------+---------+--------+----+\n",
      "|2007-07-02 00:00:00|    2914|800000|       house|       5|      null| 502800.0|    null|2007|\n",
      "|2008-06-17 00:00:00|    2914|600000|       house|       4|      null| 486800.0|800000.0|2008|\n",
      "|2008-08-29 00:00:00|    2914|465000|       house|       4|      null| 487800.0|600000.0|2008|\n",
      "|2008-09-02 00:00:00|    2914|541000|       house|       4|      null| 481450.0|465000.0|2008|\n",
      "|2008-09-05 00:00:00|    2914|395000|       house|       3|      null| 495950.0|541000.0|2008|\n",
      "+-------------------+--------+------+------------+--------+----------+---------+--------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_price = spark.sql('select * from avg_price')\n",
    "stat.withColumn('year', F.year('datesold')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stat = stat.withColumn('year', F.year('datesold'))\n",
    "stat.join(avg_price, stat.year == avg_price.YR, 'left').createOrReplaceTempView(\"result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qvh2x6_8YU3F"
   },
   "source": [
    "## Задание 3\n",
    "В итоге у вас таблица с колонками (или нечто похожее):\n",
    "*   price\n",
    "*   Среднегодовая цена\n",
    "*  Средняя стомость 10 проданных домов до текущего в том же районе (4digit postcode) (1 балл)\n",
    "*  Средняя стомость 10 проданных домов после текущего в том же районе (4digit postcode) (1 балл)\n",
    "*  Стоимость последнего проданного дома до текущего ((1 балл)\n",
    "*  и др.\n",
    "\n",
    "Посчитайте кол-во уникальных значений в каждой строчке (unique(row)). (2 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qFBmC9gvNyzl",
    "outputId": "a28d500a-d8b3-4af9-ec6e-5d8d58ab8c8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+------+------------+--------+----------+---------+--------+----+----+--------------+\n",
      "|           datesold|postcode| price|propertyType|bedrooms|avg_before|avg_after|    prev|year|  YR|year_avg_price|\n",
      "+-------------------+--------+------+------------+--------+----------+---------+--------+----+----+--------------+\n",
      "|2007-07-02 00:00:00|    2914|800000|       house|       5|      null| 502800.0|    null|2007|2007|      522377.0|\n",
      "|2008-06-17 00:00:00|    2914|600000|       house|       4|      null| 486800.0|800000.0|2008|2008|      493814.0|\n",
      "|2008-08-29 00:00:00|    2914|465000|       house|       4|      null| 487800.0|600000.0|2008|2008|      493814.0|\n",
      "|2008-09-02 00:00:00|    2914|541000|       house|       4|      null| 481450.0|465000.0|2008|2008|      493814.0|\n",
      "|2008-09-05 00:00:00|    2914|395000|       house|       3|      null| 495950.0|541000.0|2008|2008|      493814.0|\n",
      "|2008-09-05 00:00:00|    2914|552000|       house|       4|      null| 500750.0|395000.0|2008|2008|      493814.0|\n",
      "|2008-09-17 00:00:00|    2914|410000|       house|       3|      null| 505350.0|552000.0|2008|2008|      493814.0|\n",
      "|2008-09-26 00:00:00|    2914|755000|       house|       4|      null| 474250.0|410000.0|2008|2008|      493814.0|\n",
      "|2008-10-14 00:00:00|    2914|420000|       house|       4|      null| 472250.0|755000.0|2008|2008|      493814.0|\n",
      "|2008-10-16 00:00:00|    2914|375000|       house|       3|      null| 475750.0|420000.0|2008|2008|      493814.0|\n",
      "|2008-10-21 00:00:00|    2914|515000|       house|       4|  531300.0| 480250.0|375000.0|2008|2008|      493814.0|\n",
      "|2008-10-27 00:00:00|    2914|440000|       house|       3|  502800.0| 494750.0|515000.0|2008|2008|      493814.0|\n",
      "|2008-10-27 00:00:00|    2914|475000|       house|       4|  486800.0| 510250.0|440000.0|2008|2008|      493814.0|\n",
      "|2008-11-05 00:00:00|    2914|477500|       house|       4|  487800.0| 537500.0|475000.0|2008|2008|      493814.0|\n",
      "|2008-11-18 00:00:00|    2914|540000|       house|       4|  481450.0| 523500.0|477500.0|2008|2008|      493814.0|\n",
      "|2008-12-06 00:00:00|    2914|600000|       house|       4|  495950.0| 508500.0|540000.0|2008|2008|      493814.0|\n",
      "|2008-12-22 00:00:00|    2914|456000|       house|       3|  500750.0| 515400.0|600000.0|2008|2008|      493814.0|\n",
      "|2008-12-23 00:00:00|    2914|444000|       house|       4|  505350.0| 517800.0|456000.0|2008|2008|      493814.0|\n",
      "|2008-12-24 00:00:00|    2914|400000|       house|       4|  474250.0| 521300.0|444000.0|2008|2008|      493814.0|\n",
      "|2009-01-08 00:00:00|    2914|410000|       house|       4|  472250.0| 515800.0|400000.0|2009|2009|      496092.0|\n",
      "+-------------------+--------+------+------------+--------+----------+---------+--------+----+----+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "T-nHiiCpliDG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 84:====================================================> (194 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------------------------+-------------------------+------------------------------+\n",
      "|count(DISTINCT price)|count(DISTINCT avg_before)|count(DISTINCT avg_after)|count(DISTINCT year_avg_price)|\n",
      "+---------------------+--------------------------+-------------------------+------------------------------+\n",
      "|                 2554|                     15941|                    15945|                            13|\n",
      "+---------------------+--------------------------+-------------------------+------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql('select count(distinct(price)), count(distinct(avg_before)), count(distinct(avg_after)), count(distinct(year_avg_price)) from result').show()\n",
    "# остальное считать нет смысла, как по мне"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Урок 3. HW. wf_udf_joins",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
